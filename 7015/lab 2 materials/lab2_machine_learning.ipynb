{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQ-ImGC5GZBC"
   },
   "source": [
    "# COMP7015: Artificial Intelligence *(Semester 1, 2022/23)*\n",
    "\n",
    "# Lab 2: Machine Learning Basics with scikit-learn\n",
    "\n",
    "In this lab session, we will learn how to use the `scikit-learn` package for basic machine learning tasks.\n",
    "\n",
    "\n",
    "**Instructor: Dr. Kejing Yin (Department of Computer Science, Hong Kong Baptist University)**\n",
    "\n",
    "*This lab sheet is created by Dr. Kejing Yin and is licenced under MIT license.*\n",
    "\n",
    "> MIT License\n",
    "> \n",
    "> Copyright (c) 2022 Kejing Yin\n",
    "> \n",
    "> Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "> of this software and associated documentation files (the \"Software\"), to deal\n",
    "> in the Software without restriction, including without limitation the rights\n",
    "> to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "> copies of the Software, and to permit persons to whom the Software is\n",
    "> furnished to do so, subject to the following conditions:\n",
    "> \n",
    "> The above copyright notice and this permission notice shall be included in all\n",
    "> copies or substantial portions of the Software.\n",
    "> \n",
    "> THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "> IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "> FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "> AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "> LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "> OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "> SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The packages used in this lab session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Scikit-learn\n",
    "> `Scikit-learn` is an open source **machine learning library that supports supervised and unsupervised learning**. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities.\n",
    "\n",
    "It has a great tutorial, please check it out at https://scikit-learn.org/stable/tutorial/index.html\n",
    "\n",
    "## (2) Numpy\n",
    "> `NumPy` is the fundamental package for **scientific computing** in Python. It is a Python library that provides a **multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays**, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\n",
    "\n",
    "It's beginners' guide: https://numpy.org/doc/stable/user/absolute_beginners.html\n",
    "\n",
    "## (3) Pandas\n",
    "> `pandas` is a fast, powerful, flexible and easy to use open source **data analysis and manipulation tool**,\n",
    "built on top of the Python programming language.\n",
    "\n",
    "A good tutorial of Pandas: https://www.w3schools.com/python/pandas/default.asp\n",
    "\n",
    "\n",
    "In short, these three packages are fundamental for machine learning in practice. You need to master them to build a good and usable machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the packages first\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What model to use?\n",
    "https://scikit-learn.org/stable/_static/ml_map.png\n",
    "\n",
    "![image.png](https://scikit-learn.org/stable/_static/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoseHm6NkhVt"
   },
   "source": [
    "# 2. Data preparation\n",
    "\n",
    "The most essential thing for machine learning is data. Let's prepare some data for go through the upcoming tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrRH5CqePMmD"
   },
   "source": [
    "### (1) Loading external data with `pandas`\n",
    "\n",
    "`pd.read_csv`: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "`pandas` provides functions for loading dataset in various format. Here is an example of reading CSV file (iris dataset) by using `read_csv(...)` function. It returns a `pd.DataFrame` object.\n",
    "\n",
    "\n",
    "\n",
    "`pd.DataFrame`: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "> Two-dimensional, size-mutable, potentially heterogeneous tabular data. The primary pandas data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with `read_cvs` function and it returns us a ``\n",
    "housing = pd.read_csv('./ca_housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "jaITRNpdPRjj",
    "outputId": "dcf113fc-fc0b-4f56-b724-5ca8b09c018a"
   },
   "outputs": [],
   "source": [
    "# show the first five rows of the dataset\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "California Housing dataset\n",
    "--------------------------\n",
    "\n",
    "**Data Set Characteristics:**\n",
    "\n",
    "    :Number of Instances: 20640\n",
    "\n",
    "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
    "\n",
    "    :Attribute Information:\n",
    "        - MedInc        median income in block group\n",
    "        - HouseAge      median house age in block group\n",
    "        - AveRooms      average number of rooms per household\n",
    "        - AveBedrms     average number of bedrooms per household\n",
    "        - Population    block group population\n",
    "        - AveOccup      average number of household members\n",
    "        - Latitude      block group latitude\n",
    "        - Longitude     block group longitude\n",
    "\n",
    "    :Missing Attribute Values: None\n",
    "\n",
    "This dataset was obtained from the StatLib repository.\n",
    "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
    "\n",
    "**The target variable is the median house value for California districts,\n",
    "expressed in hundreds of thousands of dollars ($100,000).**\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census\n",
    "block group. A block group is the smallest geographical unit for which the U.S.\n",
    "Census Bureau publishes sample data (a block group typically has a population\n",
    "of 600 to 3,000 people).\n",
    "\n",
    "An household is a group of people residing within a home. Since the average\n",
    "number of rooms and bedrooms in this dataset are provided per household, these\n",
    "columns may take surpinsingly large values for block groups with few households\n",
    "and many empty houses, such as vacation resorts.\n",
    "\n",
    "It can be downloaded/loaded using the\n",
    ":func:`sklearn.datasets.fetch_california_housing` function.\n",
    "\n",
    "**References**\n",
    "\n",
    "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
    "      Statistics and Probability Letters, 33 (1997) 291-297"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also show the first n rows by passing an augment to this function\n",
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the last five rows of the dataset\n",
    "housing.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the shape of the dataset\n",
    "housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 20,640 rows (data samples) and 9 columns (8 attributes + 1 label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a column (`pd.Series`)\n",
    "housing['MedInc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows by index\n",
    "housing.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.iloc[2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to index a range of rows, we can simplify it to:\n",
    "housing[2:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns by index as well\n",
    "X = housing.iloc[:, :8]  # select the first eight columns (attributes/features)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get a `numpy.ndarray` representation of it by access its `.values` attribute.\n",
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = housing.iloc[:, 8]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-16q7NvSPLH1"
   },
   "source": [
    "## Exploring data\n",
    "\n",
    "After loading the dataset, it's good to take a look to the data. `.info()` would give us a summary of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ktg2CyfFXEne",
    "outputId": "6112f287-657f-4706-f37d-956c24e7d0a3"
   },
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flrr3zEN3PmM"
   },
   "source": [
    "As you could see that there are 150 entries in the DataFrame, with index `0` to `149`.\n",
    "\n",
    "`.describe()` let us know statistical detial of each column in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Fayd7n0Dct4x",
    "outputId": "05816200-0b04-4d2e-eab0-fcec741a0b28"
   },
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAVERcq-i8cr"
   },
   "source": [
    "We may have an overview of data in pair-plot with `seaborn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsEyAqEl8lQz"
   },
   "source": [
    "We have 14,448 samples for training and 6,192 samples for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PRsF3eR_VTy"
   },
   "source": [
    "# 2. Linear Regression\n",
    "\n",
    "Let's start from the simplest regression model: Lienar Regression. It fits a linear model for the data:\n",
    "\n",
    "$$\\hat{y}(w, x) = w_1 x_1 + ... + w_p x_p + b,$$\n",
    "\n",
    "where $\\hat{y}$ is the predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTSzcmBQcDgk"
   },
   "source": [
    "## (1) Hold-out method for performance evaluation\n",
    "\n",
    "Recall from the lecture content how we can evaluate the performance. Let's first try a simpler method: the hold-out method. We simply devide the data into training and test set. Then we can train the model using the training subset and measure the performance using the test subset.\n",
    "\n",
    "We can do this using the `train_test_split` function. By default, it samples training and test datasets in a stratified fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIjaFfnwcX-I"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test_size`: the size of the test subset. If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. If int, represents the absolute number of test samples. If None, the value is set to the complement of the train size. If train_size is also None, it will be set to 0.25.\n",
    "\n",
    "`train_size`: If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split. If int, represents the absolute number of train samples. If None, the value is automatically set to the complement of the test size.\n",
    "\n",
    "`random_state`: Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gfk_BQF8GbM",
    "outputId": "8469827e-1e88-46e7-ab6d-cbddbdbd6a7c"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Train a linear regression model\n",
    "We can use the `LienarRegression` model provided in `scikit-learn`:\n",
    "\n",
    "\n",
    "`LinearRegression`: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCPvR7ZiHOwk",
    "outputId": "59ebcaa5-ce1c-42ce-f9dc-ee5066b5b571"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()  # define the linear regression model\n",
    "model.fit(X_train, y_train)  # fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The weight vector is:', model.coef_)\n",
    "print()\n",
    "print('The bias is:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkbRgVQktx4v"
   },
   "source": [
    "## (2) Make predictions for new data\n",
    "\n",
    "To predict values with the estimation, we would use `.predict(input_data)` function. It would return the predicted value of `input_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aFigbz9t-cm",
    "outputId": "74eaf7a1-d53c-4b1a-ac43-eea02b5a1808"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test) # make predictions for the test data\n",
    "print(y_pred)  # it returns us a `np.ndarray` object\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Evaluate the performance: use MSE for regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can compute the MSE by the following:\n",
    "mse = ((y_test - y_pred) ** 2).mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or even easier, sklearn provides us this metric. We can use it by simply calling the corresponding function.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# sklearn.metrics.mean_squared_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average', squared=True)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They give the same results.\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also compute the MSE for the training set\n",
    "y_pred_train = model.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(mse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Use repeated hold-out method for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the lecture that hold-out method can sometimes be unstable. Let's try to repeat this process for multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Try it out!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out!\n",
    "# Copy the codes from above and modify them to train the linear regression \n",
    "# using repeated hold-out evaluation (five times)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Use K-fold Cross Validation for evaluation\n",
    "\n",
    "Recall from the lecture that K-fold cross validation is a more systematical way of evaluating the performance of machine learning models. We can do this by creating a `KFold` validator.\n",
    "\n",
    "```sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple example\n",
    "X_demo = np.array([[1, 2],\n",
    "                   [3, 4],\n",
    "                   [1, 2],\n",
    "                   [3, 4],\n",
    "                   [5, 6],\n",
    "                   [1, 2],\n",
    "                   [3, 4],\n",
    "                   [1, 2],\n",
    "                   [3, 4],\n",
    "                   [5, 6]])\n",
    "y_demo = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "print(kf.get_n_splits())  # return the number of splits\n",
    "\n",
    "for train_index, test_index in kf.split(X_demo):\n",
    "    print(\"index of training data:\", train_index, \"index of test data:\", test_index)\n",
    "    \n",
    "    X_train, X_test = X_demo[train_index], X_demo[test_index]\n",
    "    y_train, y_test = y_demo[train_index], y_demo[test_index]\n",
    "    print(X_train)\n",
    "    print(X_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Try it out!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out!\n",
    "# Copy the codes from above and modify them to train the linear regression \n",
    "# using ten-fold cross validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Dataset for classification\n",
    "\n",
    "For classification task, let's explore another simple dataset, the breast cancer wisconsin dataset. `scikit-learn` provides this dataset to us and we can get it by simply calling the `sklearn.datasets.load_breast_cancer` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 569 samples and 30 attributes for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Training a logistic regression model\n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import the model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its usage is acturally quite simple. Just define a model and fit it with data,\n",
    "# like what we did for regression.\n",
    "\n",
    "\n",
    "# for simplicity, we use hold-out method to demonstrate the model. As an after-class exercise, \n",
    "# modify it to a better evaluation method.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=15)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Making predictions for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at its output for new data\n",
    "y_preds = lr.predict(X_test)  # this will directly give us the prediction of the labels.\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can also look at the score (probability)\n",
    "y_preds_proba = lr.predict_proba(X_test)  # This now gives us V columns: V is the number of labels.\n",
    "\n",
    "y_preds_proba\n",
    "# this problem is a binary classification problem, so the first column corresponds \n",
    "# to probability of negative prediction (0) and the second column corresponds to the\n",
    "# probability of positive prediction (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we add the two columns up, the probabilities add up to one.\n",
    "y_preds_proba.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Computing the evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) The confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can show it in a pretty form\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_preds))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Accuracy, precision, recall, and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(accuracy_score(y_test, y_preds))\n",
    "print(precision_score(y_test, y_preds))\n",
    "print(recall_score(y_test, y_preds))\n",
    "print(f1_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) ROC curve and AUC score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the ROC curve by simply calling a built-in function: `sklearn.metric.RocCurveDisplay`\n",
    "\n",
    "Documentations: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "disp = RocCurveDisplay.from_estimator(lr, X_test, y_test)  # We pass the trained model and the test data to this function\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the AUC score, we can use another function provided by sklearn: `sklearn.metrics.roc_auc_score`\n",
    "\n",
    "Documentations: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(roc_auc_score(y_test, y_preds_proba[:, 1]))  # need to pass the probability of predicting positive to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the performance metric on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_train, lr.predict_proba(X_train)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is a gap between the training and testing AUC, although quite small. The `LogisticRegression` implemented in scikit-learn actually contains a regularization term. Recall from the lecture that regularization is a technique that could prevent the model from overfitting. The strength of this regularization can be controlled by an augment:\n",
    "\n",
    "- `C`: Inverse of regularization strength; must be a positive float. Smaller values specify stronger regularization.\n",
    "\n",
    "We can turn this knob and potentially it could make the model even generalize better. Such parameters that need to be specified before training a model is called \"**hyperparameters**\". The best setting of this hyperparameter is usually found by experiments and this experimenting process is called \"**hyperparameter tuning**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can try different values of `C` to see which one performs better.\n",
    "test_auc_scores = []\n",
    "for C in [0.25, 0.5, 0.75, 1, 2, 3, 4, 5, 10]:\n",
    "    lr2 = LogisticRegression(C=C)  # specify the value of C\n",
    "    lr2.fit(X_train, y_train)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, lr2.predict_proba(X_test)[:, 1])\n",
    "    test_auc_scores.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decision Tree Algorithm and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Decision Tree\n",
    "\n",
    "See the scikit-learn documentation for more details: https://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "and this one: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, scikit-learn provides us very easy-to-use API. Just simply define the model and fit the data.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion='entropy')\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn even provides us tools to visualize the decision tree learned\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "plot_tree(dtc, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "y_preds = dtc.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.predict_proba(X_test)  # the decision tree algorithm cannot give us a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Try it out!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out!\n",
    "# Compute different evaluation metrics for this decision tree classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Random Forest\n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=3)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = rf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Try it out!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out!\n",
    "# (1) Compute different evaluation metrics for this random forest classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out!\n",
    "# (2) Try to use different numbers of base learners and see how it affects the performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Multi-class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models introduced above can be used for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sklearn.datasets.load_digits(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape  # (8x8 images: 64 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  # ten classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=15)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model output will also give as the class label\n",
    "y_preds = lr.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prediction probability now has ten columns\n",
    "y_preds_proba = lr.predict_proba(X_test)\n",
    "y_preds_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can still plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_preds))\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also compute the accuracy score:\n",
    "print(accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B.**: Other evaluation metrics for multi-class classification task are more complicated. If you are interested or if you need to use them, please check them out in the scikit-learn documentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick 2-3 datasets from https://scikit-learn.org/stable/datasets.html and build machine learning models for the datasets you picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
